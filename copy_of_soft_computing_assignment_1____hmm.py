# -*- coding: utf-8 -*-
"""Copy of Soft Computing Assignment 1 __ HMM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WNEzBnA6mtUafLgvyw4yQfs9YqS_uO4C

LOAD INPUT
HERE SAMPLE_DATASET TAKES TRAINING DATA AS AN INPUT
"""

def input_data(sample_dataset):

  trainData = pd.read_csv(sample_dataset, sep="\t" ,  header = None)
  # print("type = ", type(trainData))

  #print(trainData)
  return trainData

"""FOR EMISSION MATRIX
>CALCULATE THE PROBABILITY OF DIFFERENT TEST SAMPLE AND STORED IN EMMISION MATRIX
"""

def emission_matrix_calculate(trainData):
  a = b = c = d = 0
  for i in range(len(trainData[0])):
    if(trainData[0][i] == 'fair' and trainData[1][i] == 'win'):
      a += 1
    elif(trainData[0][i] == 'fair' and trainData[1][i] == 'lose'):
      b += 1
    elif(trainData[0][i] == 'cheat' and trainData[1][i] == 'win'):
      c += 1
    elif(trainData[0][i] == 'cheat' and trainData[1][i] == 'lose'):
      d += 1

  total_fair = a + b
  total_cheat = c + d
  fair_win = a / (total_fair)
  fair_lose = b / (total_fair)
  cheat_win = c / (total_cheat)
  cheat_lose = d / (total_cheat)

  emission_matrix = np.array([fair_win, fair_lose, cheat_win, cheat_lose])
  #print(emission_matrix)
  return emission_matrix

"""FOR TRANSITION MATRIX
> CALCULATE THE PROBABILITY OF DIFFERENT STATE TRANSITION FOR TRAINING DATA
 AND VALUE STORED IN TRANSITION MATRIX FOR FURTHER CALCULATION
"""

def transition_matrix_count(trainData):
  
  fair_to_fair = fair_to_cheat = cheat_to_fair = cheat_to_cheat = 0
  for i in range(len(trainData[0]) - 1):
    if(trainData[0][i] == 'fair' and trainData[0][i + 1] == 'fair'):
      fair_to_fair += 1
    elif(trainData[0][i] == 'fair' and trainData[0][i + 1] == 'cheat'):
      fair_to_cheat += 1
    elif(trainData[0][i] == 'cheat' and trainData[0][i + 1] == 'fair'):
      cheat_to_fair += 1
    elif(trainData[0][i] == 'cheat' and trainData[0][i + 1] == 'cheat'):
      cheat_to_cheat += 1

  total_fair = fair_to_fair + fair_to_cheat;
  total_cheat = cheat_to_fair + cheat_to_cheat;

  if(trainData[0][len(trainData) - 1] == 'fair'):
    total_fair += 1
  else:
    total_cheat += 1

  f_f = fair_to_fair / total_fair
  f_c = fair_to_cheat / total_fair
  c_f = cheat_to_fair / total_cheat
  c_c = cheat_to_cheat / total_cheat
  #print("here", fair_to_fair, cheat_to_fair, total_fair, total_cheat)

  transition_matrix = np.array([f_f, f_c, c_f, c_c])
  # print(transition_matrix)
  return transition_matrix

"""INPUT_OBSERVATION FUNCTION TAKES TESTING DATA SET"""

def input_observation(testingData):
  testData = pd.read_csv(testingData, sep="\t" ,  header = None)

  #print(testData)
  return testData
#input_observation("testing_Pyramid_1000.data.txt")

"""IMPLEMENT HMM USING THE VITERBI ALGORITHM
>Reference:
Murphy, Kevin P. Machine Learning: A Probabilistic Perspective. MIT press, 2012.

![alt text](https://drive.google.com/uc?id=1J9yuHGxAKhbX67x_lmFylPzeZAKkm7Ns)
"""

def viterbi(observations, emission_matrix, initial_pro, transition_matrix):
  fair = np.zeros((len(observations)), dtype=float)
  cheat = np.zeros((len(observations)), dtype=float)

  #observations = observations.transpose()

  fair[0] = initial_pro[0] * (emission_matrix[0] if observations[0][0] == 'win' else emission_matrix[1])
  cheat[0] = initial_pro[1] * (emission_matrix[2] if observations[0][0] == 'win' else emission_matrix[3])
  
  for i in range(1, len(observations)):
    a = fair[i - 1] * transition_matrix[0] * (emission_matrix[0] if observations[0][i] == 'win' else emission_matrix[1])
    b = cheat[i - 1] * transition_matrix[2] * (emission_matrix[0] if observations[0][i] == 'win' else emission_matrix[1])
    #print(i , a, b)
    fair[i] = max(a, b)

  for i in range(1, len(observations)):
    a = cheat[i - 1] * transition_matrix[3] * (emission_matrix[2] if observations[0][i] == 'win' else emission_matrix[3])
    b = fair[i - 1] * transition_matrix[1] * (emission_matrix[2] if observations[0][i] == 'win' else emission_matrix[3])
    #print(i , a, b)
    cheat[i] = max(a, b)

  for i in range(len(observations)):
    print("F" if fair[i] >= cheat[i] else "C")
  

  print("fair: ", fair)
  print("cheat:", cheat)


  #print(fair[0], fair[1], cheat[0])

"""MAIN FUNCTION"""

import numpy as np

def main():

    sample_dataset = "training_Dragon_1000.data.txt"  
    testing_data = "testing_Dragon_1000.data.txt"     
    #testing_data = "class_sample.txt"

    observations = input_observation(testing_data)
    initial_pro = np.array([0.5, 0.5])

    trainData = input_data(sample_dataset)

    emission_matrix = emission_matrix_calculate(trainData)
    transition_matrix = transition_matrix_count(trainData)

    # #here
    # transition_matrix = np.array([0.9, 0.1, 0.1, 0.9])
    # emission_matrix = np.array([0.5, 0.5, 0.75, 0.25])
    # #here

    print("Transition Matrix\n", transition_matrix)
    print("Emission Matrix\n", emission_matrix)

    viterbi(observations, emission_matrix, initial_pro, transition_matrix)
    # score, final_output = viterbi(observations, emission_matrix, initial_pro, transition_matrix)

main()



